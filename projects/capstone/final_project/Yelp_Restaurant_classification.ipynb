{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: Yelp Restaurant Photo Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import sys\n",
    "\n",
    "import caffe\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import rotate\n",
    "from skimage.exposure import adjust_gamma\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define caffe and dataset root\n",
    "caffe_root = '/home/ubuntu/src/caffe/'\n",
    "dataset_root = '/home/ubuntu/yelp_classification/data/'\n",
    "\n",
    "test_dataset_root = '/home/ubuntu/'\n",
    "\n",
    "# Using python, so insert python into caffe root\n",
    "sys.path.insert(0, caffe_root + 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 234842\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Training set\n",
    "############################\n",
    "\n",
    "train_photos_to_business_id = pd.read_csv(dataset_root + 'train_photo_to_biz_ids.csv')\n",
    "\n",
    "business_frequency_list = []\n",
    "count = 0\n",
    "for photo in train_photos_to_business_id['photo_id']:\n",
    "    business_frequency_list.append(train_photos_to_business_id.loc[count]['business_id'])\n",
    "    count += 1\n",
    "    \n",
    "print('Number of training images: {}'.format(len(business_frequency_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum photos in a business for training set: 2974\n",
      "Minimum photos in a business for training set: 2\n",
      "Average photos in a business for training set: 117\n"
     ]
    }
   ],
   "source": [
    "biz_frequency_dict = Counter(business_frequency_list)\n",
    "\n",
    "biz_values = biz_frequency_dict.values()\n",
    "\n",
    "biz_total_photos = sum(biz_values)\n",
    "biz_list_len = len(biz_frequency_dict.keys())\n",
    "\n",
    "biz_max_photos = max(biz_values)\n",
    "biz_min_photos = min(biz_values)\n",
    "\n",
    "print('Maximum photos in a business for training set: {}'.format(biz_max_photos))\n",
    "print('Minimum photos in a business for training set: {}'.format(biz_min_photos))\n",
    "\n",
    "print('Average photos in a business for training set: {}'.format((biz_total_photos/biz_list_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190225\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Testing set\n",
    "############################\n",
    "\n",
    "test_photos_to_business_id = pd.read_csv(dataset_root + 'test_photo_to_biz.csv')\n",
    "\n",
    "test_biz_freq_list = []\n",
    "\n",
    "count = 0\n",
    "for photo in test_photos_to_business_id['photo_id']:\n",
    "    test_biz_freq_list.append(test_photos_to_business_id.loc[count]['business_id'])\n",
    "    count += 1\n",
    "    \n",
    "print(len(test_biz_freq_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum photos in a business for testing set: 2825\n",
      "Minimum photos in a business for testing set: 1\n",
      "Average photos in a business for testing set: 119\n"
     ]
    }
   ],
   "source": [
    "test_biz_freq_dict = Counter(test_biz_freq_list)\n",
    "\n",
    "biz_values = test_biz_freq_dict.values()\n",
    "\n",
    "biz_total_photos = sum(biz_values)\n",
    "biz_list_len = len(test_biz_freq_dict.keys())\n",
    "\n",
    "biz_max_photos = max(biz_values)\n",
    "biz_min_photos = min(biz_values)\n",
    "\n",
    "print('Maximum photos in a business for testing set: {}'.format(biz_max_photos))\n",
    "print('Minimum photos in a business for testing set: {}'.format(biz_min_photos))\n",
    "\n",
    "print('Average photos in a business for testing set: {}'.format((biz_total_photos/biz_list_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero labeled business in train set: 4\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Visualizing Training set\n",
    "############################\n",
    "\n",
    "y_training_labels = pd.read_csv(dataset_root + 'train.csv')\n",
    "\n",
    "list_of_labels = []\n",
    "count_of_non_zero_labels = 0\n",
    "\n",
    "total_count = 0\n",
    "for labels in y_training_labels['labels']:\n",
    "    if (type(labels) is str):\n",
    "        label_list = labels.split(' ')\n",
    "        list_of_labels.append(label_list)\n",
    "        count_of_non_zero_labels += 1\n",
    "    \n",
    "    total_count += 1\n",
    "\n",
    "list_of_labels = np.concatenate(list_of_labels)\n",
    "\n",
    "frequency_list = Counter(list_of_labels)\n",
    "\n",
    "print('Number of zero labeled business in train set: {}'.format((total_count - count_of_non_zero_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEhCAYAAABoTkdHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWbv8f2q/iEwtlMvWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f641a8159d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting bar chart\n",
    "\n",
    "N = len(frequency_list)\n",
    "keys = list(frequency_list.keys())\n",
    "values = list(frequency_list.values())\n",
    "\n",
    "plt.bar(range(N), values, align='center')\n",
    "plt.xticks(range(N), keys)\n",
    "plt.ylabel('Number of Businesses associated with particular label')\n",
    "plt.xlabel('Label for a restaurant')\n",
    "plt.title('Frequency of businesses per label in training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of training set with labels\n",
      "\n",
      "   business_id         labels\n",
      "0         1000  1 2 3 4 5 6 7\n",
      "1         1001        0 1 6 8\n",
      "2          100    1 2 4 5 6 7\n",
      "3         1006      1 2 4 5 6\n",
      "4         1010          0 6 8\n"
     ]
    }
   ],
   "source": [
    "print('Sample of training set with labels\\n')\n",
    "print(y_training_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of training photos to training business ids\n",
      "\n",
      "   photo_id  business_id\n",
      "0    204149         3034\n",
      "1     52779         2805\n",
      "2    278973          485\n",
      "3    195284          485\n",
      "4     19992          485\n"
     ]
    }
   ],
   "source": [
    "## Load mapping of Training Photos to Business IDs\n",
    "train_photos_to_business_id = pd.read_csv(dataset_root + 'train_photo_to_biz_ids.csv')\n",
    "\n",
    "print('Mapping of training photos to training business ids\\n')\n",
    "print(train_photos_to_business_id[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of testing photos to training business ids\n",
      "\n",
      "      photo_id business_id\n",
      "1000    238721       021oz\n",
      "1001    407713       021oz\n",
      "1002    223604       021oz\n",
      "1003    408898       021oz\n",
      "1004    276062       021oz\n"
     ]
    }
   ],
   "source": [
    "## Load mapping of Testing Photos to Business IDs\n",
    "test_photos_to_business_id = pd.read_csv(dataset_root + 'test_photo_to_biz.csv')\n",
    "\n",
    "print('Mapping of testing photos to training business ids\\n')\n",
    "print(test_photos_to_business_id[1000:1005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total augmented businesses: 1352\n"
     ]
    }
   ],
   "source": [
    "## Data Augmentation\n",
    "\n",
    "# Create a DataFrame consisting of all the businesses that have either 0, 4 or 7 in their labels\n",
    "# This is done as these classes have less data points.\n",
    "\n",
    "list_of_businesses = []\n",
    "list_of_augmented_labels = []\n",
    "\n",
    "aug_label_dict = {}\n",
    "aug_label_dict_2 = {}\n",
    "count = 0\n",
    "for labels, biz_id in zip(y_training_labels['labels'], y_training_labels['business_id']):\n",
    "    if ( (type(labels) is str) and ( ('0' in labels) or ('4' in labels) or ('7' in labels) ) ):\n",
    "        list_of_businesses.append(biz_id)\n",
    "        list_of_augmented_labels.append(labels)\n",
    "        aug_label_dict[biz_id] = labels\n",
    "\n",
    "\n",
    "print('Total augmented businesses: {}'.format(len(list_of_businesses)))\n",
    "\n",
    "\n",
    "aug_label_dict_2['business_id'] = list_of_businesses\n",
    "aug_label_dict_2['labels'] = list_of_augmented_labels\n",
    "\n",
    "aug_label_dataframe = pd.DataFrame(data=aug_label_dict_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 10000\n",
      "Processed: 20000\n",
      "Processed: 30000\n",
      "Processed: 40000\n",
      "Processed: 50000\n",
      "Processed: 60000\n",
      "Processed: 70000\n",
      "Processed: 80000\n",
      "Processed: 90000\n",
      "Processed: 100000\n",
      "Processed: 110000\n",
      "Processed: 120000\n",
      "Processed: 130000\n",
      "Processed: 140000\n",
      "Processed: 150000\n",
      "Processed: 160000\n",
      "167775\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame to store augmented photo_id for all the businesses found in previous step\n",
    "aug_data_frame = pd.DataFrame(columns=['photo_id', 'business_id'])\n",
    "\n",
    "count = 0\n",
    "\n",
    "aug_image_list = []\n",
    "aug_biz_list = []\n",
    "aug_label_list = []\n",
    "\n",
    "aug_img_dataset_dict = {}\n",
    "\n",
    "# Go through all the rows in 'train_photos_to_business_id' and save only the photos whose \n",
    "# business id matches in augmented dataframe created earlier\n",
    "for photo_id, biz_id in zip(train_photos_to_business_id['photo_id'], train_photos_to_business_id['business_id']):\n",
    "    if biz_id in list_of_businesses:\n",
    "        # Business matched, store photo_id, business_id and labels\n",
    "        index_list = aug_label_dataframe.index[aug_label_dataframe['business_id'] == biz_id].tolist()\n",
    "        aug_image_list.append(photo_id)\n",
    "        aug_biz_list.append(biz_id)\n",
    "        aug_label_list.append(aug_label_dataframe.at[index_list[0], 'labels'])\n",
    "        count += 1\n",
    "        \n",
    "        if (count%10000) == 0:\n",
    "            print('Processed: {}'.format(count))\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 2 3 5 6 7', '1 2 3 4 5 6 7', '1 2 3 4 5 6 7', '1 2 3 4 5 6 7', '1 2 3 4 5 6 7']\n",
      "['7', '4 7', '4 7', '4 7', '4 7']\n",
      "167775\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Process labels so that they only contain (0, 4, 7)\n",
    "print(aug_label_list[:5])\n",
    "\n",
    "aug_reduced_label_list = []\n",
    "for single_row_labels in aug_label_list:\n",
    "    labels_list = [int(i) for i in single_row_labels.split()]\n",
    "    reduced_label_list = np.intersect1d(labels_list, [0, 4, 7])\n",
    "\n",
    "    reduced_label_string = \" \".join([str(i) for i in reduced_label_list])\n",
    "    aug_reduced_label_list.append(reduced_label_string)\n",
    "\n",
    "print(aug_reduced_label_list[:5])\n",
    "print(len(aug_reduced_label_list))\n",
    "print('Done')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Create a final dataframe consisting of photo_id, business_id and 'reduced' label list having [0, 4 or 7]\n",
    "aug_img_dataset_dict['photo_id'] = aug_image_list\n",
    "aug_img_dataset_dict['business_id'] = aug_biz_list\n",
    "aug_img_dataset_dict['labels'] = aug_reduced_label_list\n",
    "\n",
    "aug_data_frame = pd.DataFrame(data=aug_img_dataset_dict)\n",
    "\n",
    "# Store aug data frame to file\n",
    "with open(dataset_root + \"augmented_photo_to_business_id.csv\", 'w') as f:  \n",
    "    aug_data_frame.to_csv(f, index=False)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   business_id labels  photo_id\n",
      "0         2805      7     52779\n",
      "1          485    4 7    278973\n",
      "2          485    4 7    195284\n",
      "3          485    4 7     19992\n",
      "4          485    4 7     80748\n"
     ]
    }
   ],
   "source": [
    "aug_data_frame = pd.read_csv(dataset_root + 'augmented_photo_to_business_id.csv')\n",
    "print(aug_data_frame.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Create augmented images and store them (rotation and gamma correction)\n",
    "###########################################\n",
    "\n",
    "aug_root = '/home/ubuntu/aug_test_photos/'\n",
    "def create_augmented_data(aug_frame):\n",
    "    \n",
    "    #Rotate image by 90 degree\n",
    "    photo_ids_list = aug_data_frame['photo_id']\n",
    "    \n",
    "    count = 0\n",
    "    for each_photo_id in photo_ids_list:\n",
    "        photo_path = os.path.join(dataset_root + 'train_photos/', str(each_photo_id) + '.jpg')\n",
    "        #print photo_path\n",
    "    \n",
    "        # Read image using scikit learn\n",
    "        photo = io.imread(photo_path)\n",
    "        \n",
    "        rotation_choice_list = [90, 180, 270]\n",
    "        \n",
    "        # Rotate image by either 90, 180 or 270 degrees\n",
    "        rotated_image = rotate(photo, random.choice(rotation_choice_list), resize=True)\n",
    "\n",
    "        gamma_list = [0.25, 0.5, 2]\n",
    "\n",
    "        # Adjust gamma of image\n",
    "        gamma_adjusted_image = adjust_gamma(photo, random.choice(gamma_list))\n",
    "\n",
    "        # Save rotate image and gamma adjusted image\n",
    "        io.imsave(aug_root+str(each_photo_id)+'_rotated.jpg', rotated_image)\n",
    "        io.imsave(aug_root+str(each_photo_id)+'_gamma.jpg', gamma_adjusted_image)\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if (count % 10000) == 0:\n",
    "            print('Processed uptil now: {}'.format(count))\n",
    "    \n",
    "    print('Saved total images: '.format(count))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(count)\n",
    "create_augmented_data(aug_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe consisting of augmented image names (rotated and gamma appended) in prev augmented dataframe\n",
    "\n",
    "def save_rotated_augmented_dataframe(aug_data_frame):\n",
    "    aug_data_frame_copy = aug_data_frame.copy()\n",
    "    \n",
    "    photos_id_list = aug_data_frame_copy['photo_id']\n",
    "    photos_id_rotated_list = []\n",
    "    \n",
    "    for photos_id in photos_id_list:\n",
    "        photos_id_rotated_list.append(str(photos_id)+'_rotated')\n",
    "\n",
    "    aug_rotated_img_dataset_dict = {}\n",
    "    aug_rotated_img_dataset_dict['photo_id'] = photos_id_rotated_list\n",
    "\n",
    "    aug_data_frame_copy['photo_id'] = aug_rotated_img_dataset_dict['photo_id']\n",
    "    \n",
    "    with open(dataset_root + \"augmented_photo_to_business_id_rotated.csv\", 'w') as f:  \n",
    "        aug_data_frame_copy.to_csv(f, index=False)\n",
    "        \n",
    "    print('Saved rotated augmented data.')\n",
    "    \n",
    "\n",
    "    \n",
    "def save_gamma_adjusted_augmented_dataframe(aug_data_frame):\n",
    "    aug_data_frame_copy = aug_data_frame.copy()\n",
    "    \n",
    "    photos_id_list = aug_data_frame_copy['photo_id']\n",
    "    photos_id_gamma_adjusted_list = []\n",
    "    \n",
    "    for photos_id in photos_id_list:\n",
    "        photos_id_gamma_adjusted_list.append(str(photos_id)+'_gamma')\n",
    "\n",
    "\n",
    "    aug_gamma_adjusted_img_dataset_dict = {}\n",
    "    aug_gamma_adjusted_img_dataset_dict['photo_id'] = photos_id_gamma_adjusted_list\n",
    "\n",
    "    aug_data_frame_copy['photo_id'] = aug_gamma_adjusted_img_dataset_dict['photo_id']\n",
    "    \n",
    "    with open(dataset_root + \"augmented_photo_to_business_id_gamma_adjusted.csv\", 'w') as f:  \n",
    "        aug_data_frame_copy.to_csv(f, index=False)\n",
    "        \n",
    "    print('Saved gamma adjusted augmented data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rotated augmented data.\n",
      "Saved gamma adjusted augmented data.\n"
     ]
    }
   ],
   "source": [
    "save_rotated_augmented_dataframe(aug_data_frame)\n",
    "save_gamma_adjusted_augmented_dataframe(aug_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   business_id labels        photo_id\n",
      "0         2805      7   52779_rotated\n",
      "1          485    4 7  278973_rotated\n",
      "2          485    4 7  195284_rotated\n",
      "3          485    4 7   19992_rotated\n",
      "4          485    4 7   80748_rotated\n"
     ]
    }
   ],
   "source": [
    "aug_rotated_data_frame = pd.read_csv(dataset_root + 'augmented_photo_to_business_id_rotated.csv')\n",
    "print(aug_rotated_data_frame.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   business_id labels      photo_id\n",
      "0         2805      7   52779_gamma\n",
      "1          485    4 7  278973_gamma\n",
      "2          485    4 7  195284_gamma\n",
      "3          485    4 7   19992_gamma\n",
      "4          485    4 7   80748_gamma\n"
     ]
    }
   ],
   "source": [
    "aug_gamma_data_frame = pd.read_csv(dataset_root + 'augmented_photo_to_business_id_gamma_adjusted.csv')\n",
    "print(aug_gamma_data_frame.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Caffe Pre-trained Reference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaffeNet found.\n"
     ]
    }
   ],
   "source": [
    "# Check to see if CaffeNet is already downloaded, otherwise download it\n",
    "if os.path.isfile(caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
    "    print('CaffeNet found.')\n",
    "else:\n",
    "    print('Downloading pre-trained CaffeNet model...')\n",
    "    !/home/ubuntu/src/caffe/scripts/download_model_binary.py /home/ubuntu/src/caffe/models/bvlc_reference_caffenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use GPU    \n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Image features from the second last layer ('fc7') of CaffeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(image_list, layer = 'fc7'):\n",
    "    \n",
    "    #######################################################################################\n",
    "    # Reference: https://github.com/BVLC/caffe/blob/master/examples/00-classification.ipynb\n",
    "    #######################################################################################\n",
    "\n",
    "    # BVLC Caffenet model definition (layers etc)\n",
    "    proto_file = caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "    \n",
    "    # BVLC Caffenet learned model weights\n",
    "    caffemodel = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "\n",
    "    # Create a caffe 'Net'\n",
    "    caffe_net = caffe.Net(proto_file, caffemodel, caffe.TEST)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Pre-process the input images in form Caffe expects\n",
    "    \n",
    "    # Mean from image net\n",
    "    mean_imagenet = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "    \n",
    "    # average over pixels to obtain the mean (BGR) pixel values\n",
    "    mean = mean_imagenet.mean(1).mean(1)\n",
    "    \n",
    "    \n",
    "    # Create a transformer for loading images in form of caffenet and name it 'data'\n",
    "    \n",
    "    # By default the caffe transformer returns data shape as (10, 3, 227, 227).\n",
    "    # This is because 10 random 227x227 crops are supposed to be extracted from a 256x256 image \n",
    "    # and passed through the net.\n",
    "    transformer = caffe.io.Transformer({'data': caffe_net.blobs['data'].data.shape})\n",
    "    \n",
    "    # Transform image channels, input is (HxWxC) while caffe expects (CxHxW)\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "\n",
    "    # subtract the dataset-mean value in each channel\n",
    "    transformer.set_mean('data', mean)\n",
    "    \n",
    "    # rescale image data from [0, 1] to [0, 255] as caffe operates on images in range [0, 255] \n",
    "    transformer.set_raw_scale('data', 255)\n",
    "    \n",
    "    # Caffe expects images in BGR format while input is in RGB format, so swap it\n",
    "    transformer.set_channel_swap('data', (2,1,0))\n",
    "\n",
    "    \n",
    "    \n",
    "    total_images = len(image_list)\n",
    "    \n",
    "    # set the size of the input (batch_size, channel, height, width)\n",
    "    caffe_net.blobs['data'].reshape(total_images, 3, 227, 227)\n",
    "    \n",
    "    # Load the images and transform them and save it in memory\n",
    "    caffe_net.blobs['data'].data[...] = map(lambda img: transformer.preprocess('data', caffe.io.load_image(img)), image_list)\n",
    "    \n",
    "    ### perform classification using BVLC reference model 'caffe_net' created earlier\n",
    "    out = caffe_net.forward()\n",
    "\n",
    "    # Return the 'fc7' layer weights features\n",
    "    return caffe_net.blobs[layer].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from training images and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Train image features file!\n"
     ]
    }
   ],
   "source": [
    "# Save the extracted features for both test and train images for later use using H5PY library\n",
    "\n",
    "# Read and close file first\n",
    "h5py_train_file = h5py.File(dataset_root + 'train_images_fc7_features.h5', 'r+')\n",
    "h5py_train_file.close()\n",
    "\n",
    "\n",
    "\n",
    "# Open a h5py file for writing training features extracted using bvlc reference model\n",
    "h5py_train_file = h5py.File(dataset_root + 'train_images_fc7_features.h5','w')\n",
    "\n",
    "# Create dataset for image name\n",
    "h5py_train_img_name = h5py_train_file.create_dataset('image_name', (0,), maxshape=(None,), dtype='|S54')\n",
    "\n",
    "# Create dataset for image features\n",
    "# Save features returned from bvlc fc7 layer (4096 features) to h5py file\n",
    "h5py_train_img_feature = h5py_train_file.create_dataset('image_feature', (0,4096), maxshape = (None,4096))\n",
    "\n",
    "h5py_train_file.close()\n",
    "\n",
    "print(\"Created Train image features file!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 234842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the Image full path using photo list from csv file\n",
    "train_images = [os.path.join(dataset_root + 'train_photos/', str(x) + '.jpg') for x in train_photos_to_business_id['photo_id']]\n",
    "\n",
    "total_train_images = len(train_images)\n",
    "print(\"Total training images: {}\".format(total_train_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images processed: 10000\n",
      "Total images processed: 20000\n",
      "Total images processed: 30000\n",
      "Total images processed: 40000\n",
      "Total images processed: 50000\n",
      "Total images processed: 60000\n",
      "Total images processed: 70000\n",
      "Total images processed: 80000\n",
      "Total images processed: 90000\n",
      "Total images processed: 100000\n",
      "Total images processed: 110000\n",
      "Total images processed: 120000\n",
      "Total images processed: 130000\n",
      "Total images processed: 140000\n",
      "Total images processed: 150000\n",
      "Total images processed: 160000\n",
      "Total images processed: 170000\n",
      "Total images processed: 180000\n",
      "Total images processed: 190000\n",
      "Total images processed: 200000\n",
      "Total images processed: 210000\n",
      "Total images processed: 220000\n",
      "Total images processed: 230000\n",
      "Total images processed: 234842\n"
     ]
    }
   ],
   "source": [
    "# Batch size to process image features\n",
    "batch_size = 500\n",
    "\n",
    "# Get the features for training Images\n",
    "for count in range(0, total_train_images, batch_size):\n",
    "    \n",
    "    # Get the image path for this batch of images\n",
    "    image_path = train_images[count: min((count + batch_size), total_train_images)]\n",
    "    \n",
    "    # Get features for all batch images\n",
    "    train_img_features = load_features(image_path, layer='fc7')\n",
    "    \n",
    "    total_processed = count + train_img_features.shape[0]\n",
    "\n",
    "    \n",
    "    # Open the h5 file to store the image features for future use\n",
    "    h5py_train_file = h5py.File(dataset_root + 'train_images_fc7_features.h5','r+')\n",
    "    \n",
    "    h5py_train_file['image_name'].resize((total_processed,))\n",
    "    h5py_train_file['image_name'][count : total_processed] = np.array(image_path)\n",
    "    \n",
    "    h5py_train_file['image_feature'].resize((total_processed, train_img_features.shape[1]))\n",
    "    h5py_train_file['image_feature'][count : total_processed, :] = train_img_features\n",
    "    h5py_train_file.close()\n",
    "\n",
    "    if (total_processed % 10000) == 0 or total_processed == total_train_images:\n",
    "        print(\"Total images processed: {}\".format(total_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ubuntu/yelp_classification/data/train_photos/807'\n",
      " '/home/ubuntu/yelp_classification/data/train_photos/444'\n",
      " '/home/ubuntu/yelp_classification/data/train_photos/200'\n",
      " '/home/ubuntu/yelp_classification/data/train_photos/905'\n",
      " '/home/ubuntu/yelp_classification/data/train_photos/275']\n",
      "[ 0.          2.72086954  0.          0.32762367  0.        ]\n",
      "[ 1.82701159  0.          0.          2.56912136  0.        ]\n",
      "[ 0.          0.          0.          0.          1.09389067]\n",
      "[ 0.80203223  0.49244475  0.          1.40174103  0.52880692]\n",
      "[ 0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "h5py_train_file = h5py.File(dataset_root + 'train_images_fc7_features.h5', 'r+')\n",
    "print(h5py_train_file['image_name'][5:10])\n",
    "print(h5py_train_file['image_feature'][5][:5])\n",
    "print(h5py_train_file['image_feature'][6][:5])\n",
    "print(h5py_train_file['image_feature'][7][:5])\n",
    "print(h5py_train_file['image_feature'][8][:5])\n",
    "print(h5py_train_file['image_feature'][9][:5])\n",
    "h5py_train_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from augmented training images and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Augmented rotated Train image features file!\n",
      "Created Augmented gamma adjusted Train image features file!\n"
     ]
    }
   ],
   "source": [
    "# Read and close file first\n",
    "#h5py_aug_rotated_train_file = h5py.File(data_loc + 'aug_rotated_train_images_fc7_features.h5', 'r+')\n",
    "#h5py_aug_rotated_train_file.close()\n",
    "\n",
    "\n",
    "# Open a h5py file for writing training features extracted using bvlc reference model\n",
    "h5py_aug_rotated_train_file = h5py.File(dataset_root + 'aug_rotated_train_images_fc7_features.h5','w')\n",
    "\n",
    "# Create dataset for image name\n",
    "h5py_aug_rotated_train_img_name = h5py_aug_rotated_train_file.create_dataset('image_name', (0,), maxshape=(None,), dtype='|S54')\n",
    "\n",
    "# Create dataset for image features\n",
    "# Save features returned from bvlc fc7 layer (4096 features) to h5py file\n",
    "h5py_aug_rotated_train_img_feature = h5py_aug_rotated_train_file.create_dataset('image_feature', (0,4096), maxshape = (None,4096))\n",
    "\n",
    "h5py_aug_rotated_train_file.close()\n",
    "\n",
    "print(\"Created Augmented rotated Train image features file!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open a h5py file for writing training features extracted using bvlc reference model\n",
    "h5py_aug_gamma_train_file = h5py.File(dataset_root + 'aug_gamma_train_images_fc7_features.h5','w')\n",
    "\n",
    "# Create dataset for image name\n",
    "h5py_aug_gamma_train_img_name = h5py_aug_gamma_train_file.create_dataset('image_name', (0,), maxshape=(None,), dtype='|S54')\n",
    "\n",
    "# Create dataset for image features\n",
    "# Save features returned from bvlc fc7 layer (4096 features) to h5py file\n",
    "h5py_aug_gamma_train_img_feature = h5py_aug_gamma_train_file.create_dataset('image_feature', (0,4096), maxshape = (None,4096))\n",
    "\n",
    "h5py_aug_gamma_train_file.close()\n",
    "\n",
    "print(\"Created Augmented gamma adjusted Train image features file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total augmented rotated training images: 167775\n",
      "Total augmented gamma adjusted training images: 167775\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the Image full path using photo list from csv file\n",
    "aug_rotated_train_images = [os.path.join(aug_root, str(x) + '.jpg') for x in aug_rotated_data_frame['photo_id']]\n",
    "\n",
    "total_aug_rotated_train_images = len(aug_rotated_train_images)\n",
    "print(\"Total augmented rotated training images: {}\".format(total_aug_rotated_train_images))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the Image full path using photo list from csv file\n",
    "aug_gamma_train_images = [os.path.join(aug_root, str(x) + '.jpg') for x in aug_gamma_data_frame['photo_id']]\n",
    "\n",
    "total_aug_gamma_train_images = len(aug_gamma_train_images)\n",
    "print(\"Total augmented gamma adjusted training images: {}\".format(total_aug_gamma_train_images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total augmented rotated images processed: 10000\n",
      "Total augmented rotated images processed: 20000\n",
      "Total augmented rotated images processed: 30000\n",
      "Total augmented rotated images processed: 40000\n",
      "Total augmented rotated images processed: 50000\n",
      "Total augmented rotated images processed: 60000\n",
      "Total augmented rotated images processed: 70000\n",
      "Total augmented rotated images processed: 80000\n",
      "Total augmented rotated images processed: 90000\n",
      "Total augmented rotated images processed: 100000\n",
      "Total augmented rotated images processed: 110000\n",
      "Total augmented rotated images processed: 120000\n",
      "Total augmented rotated images processed: 130000\n",
      "Total augmented rotated images processed: 140000\n",
      "Total augmented rotated images processed: 150000\n",
      "Total augmented rotated images processed: 160000\n",
      "Total augmented rotated images processed: 167775\n"
     ]
    }
   ],
   "source": [
    "# Batch size to process image features\n",
    "batch_size = 500\n",
    "\n",
    "# Get the features for augmented rotated training Images\n",
    "for count in range(0, total_aug_rotated_train_images, batch_size):\n",
    "    \n",
    "    # Get the image path for this batch of images\n",
    "    image_path = aug_rotated_train_images[count: min((count + batch_size), total_aug_rotated_train_images)]\n",
    "    \n",
    "    # Get features for all batch images\n",
    "    aug_rot_train_img_features = load_features(image_path, layer='fc7')\n",
    "    \n",
    "    total_processed = count + aug_rot_train_img_features.shape[0]\n",
    "\n",
    "    \n",
    "    # Open the h5 file to store the image features for future use\n",
    "    h5py_aug_rotated_train_file = h5py.File(dataset_root + 'aug_rotated_train_images_fc7_features.h5','r+')\n",
    "    \n",
    "    h5py_aug_rotated_train_file['image_name'].resize((total_processed,))\n",
    "    h5py_aug_rotated_train_file['image_name'][count : total_processed] = np.array(image_path)\n",
    "    \n",
    "    h5py_aug_rotated_train_file['image_feature'].resize((total_processed, aug_rot_train_img_features.shape[1]))\n",
    "    h5py_aug_rotated_train_file['image_feature'][count : total_processed, :] = aug_rot_train_img_features\n",
    "    h5py_aug_rotated_train_file.close()\n",
    "\n",
    "    if (total_processed % 10000) == 0 or total_processed == total_aug_rotated_train_images:\n",
    "        print(\"Total augmented rotated images processed: {}\".format(total_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total augmented gamma adjusted images processed: 10000\n",
      "Total augmented gamma adjusted images processed: 20000\n",
      "Total augmented gamma adjusted images processed: 30000\n",
      "Total augmented gamma adjusted images processed: 40000\n",
      "Total augmented gamma adjusted images processed: 50000\n",
      "Total augmented gamma adjusted images processed: 60000\n",
      "Total augmented gamma adjusted images processed: 70000\n",
      "Total augmented gamma adjusted images processed: 80000\n",
      "Total augmented gamma adjusted images processed: 90000\n",
      "Total augmented gamma adjusted images processed: 100000\n",
      "Total augmented gamma adjusted images processed: 110000\n",
      "Total augmented gamma adjusted images processed: 120000\n",
      "Total augmented gamma adjusted images processed: 130000\n",
      "Total augmented gamma adjusted images processed: 140000\n",
      "Total augmented gamma adjusted images processed: 150000\n",
      "Total augmented gamma adjusted images processed: 160000\n",
      "Total augmented gamma adjusted images processed: 167775\n"
     ]
    }
   ],
   "source": [
    "# Batch size to process image features\n",
    "batch_size = 500\n",
    "\n",
    "# Get the features for augmented rotated training Images\n",
    "for count in range(0, total_aug_gamma_train_images, batch_size):\n",
    "    \n",
    "    # Get the image path for this batch of images\n",
    "    image_path = aug_gamma_train_images[count: min((count + batch_size), total_aug_gamma_train_images)]\n",
    "    \n",
    "    # Get features for all batch images\n",
    "    aug_gamma_train_img_features = load_features(image_path, layer='fc7')\n",
    "    \n",
    "    total_processed = count + aug_gamma_train_img_features.shape[0]\n",
    "\n",
    "    \n",
    "    # Open the h5 file to store the image features for future use\n",
    "    h5py_aug_gamma_train_file = h5py.File(dataset_root + 'aug_gamma_train_images_fc7_features.h5','r+')\n",
    "    \n",
    "    h5py_aug_gamma_train_file['image_name'].resize((total_processed,))\n",
    "    h5py_aug_gamma_train_file['image_name'][count : total_processed] = np.array(image_path)\n",
    "    \n",
    "    h5py_aug_gamma_train_file['image_feature'].resize((total_processed, aug_gamma_train_img_features.shape[1]))\n",
    "    h5py_aug_gamma_train_file['image_feature'][count : total_processed, :] = aug_gamma_train_img_features\n",
    "    h5py_aug_gamma_train_file.close()\n",
    "\n",
    "    if (total_processed % 10000) == 0 or total_processed == total_aug_gamma_train_images:\n",
    "        print(\"Total augmented gamma adjusted images processed: {}\".format(total_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero labeled business in train set: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_training_labels = pd.read_csv(dataset_root + 'train.csv')\n",
    "\n",
    "list_of_labels = []\n",
    "count_of_non_zero_labels = 0\n",
    "\n",
    "total_count = 0\n",
    "for labels in y_training_labels['labels']:\n",
    "    if (type(labels) is str):\n",
    "        label_list = labels.split(' ')\n",
    "        list_of_labels.append(label_list)\n",
    "        count_of_non_zero_labels += 1\n",
    "    \n",
    "    total_count += 1\n",
    "\n",
    "    \n",
    "#Augmented data\n",
    "for labels in list_of_augmented_labels:\n",
    "    if (type(labels) is str):\n",
    "        labels_list = [int(i) for i in labels.split()]\n",
    "        reduced_label_list = np.intersect1d(labels_list, [0, 4, 7])\n",
    "\n",
    "        reduced_label_string = \" \".join([str(i) for i in reduced_label_list])\n",
    "        \n",
    "        label_list = reduced_label_string.split(' ')\n",
    "        list_of_labels.append(label_list)\n",
    "        \n",
    "        count_of_non_zero_labels += 1\n",
    "    \n",
    "    total_count += 1\n",
    "\n",
    "\n",
    "for labels in list_of_augmented_labels:\n",
    "    if (type(labels) is str):\n",
    "        labels_list = [int(i) for i in labels.split()]\n",
    "        reduced_label_list = np.intersect1d(labels_list, [0, 4, 7])\n",
    "\n",
    "        reduced_label_string = \" \".join([str(i) for i in reduced_label_list])\n",
    "        \n",
    "        label_list = reduced_label_string.split(' ')\n",
    "        list_of_labels.append(label_list)\n",
    "        \n",
    "        count_of_non_zero_labels += 1\n",
    "    \n",
    "    total_count += 1\n",
    "\n",
    "\n",
    "list_of_labels = np.concatenate(list_of_labels)\n",
    "frequency_list = Counter(list_of_labels)\n",
    "\n",
    "print('Number of zero labeled business in train set: {}'.format((total_count - count_of_non_zero_labels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEhCAYAAACgIq2RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad7bbb6f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting bar chart\n",
    "\n",
    "N = len(frequency_list)\n",
    "keys = list(frequency_list.keys())\n",
    "values = list(frequency_list.values())\n",
    "\n",
    "plt.bar(range(N), values, align='center')\n",
    "plt.xticks(range(N), keys)\n",
    "plt.ylabel('Number of Businesses associated with particular label')\n",
    "plt.xlabel('Label for a restaurant')\n",
    "plt.title('Frequency of businesses per label in \\'Augmented\\' training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from Testing images and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Test image features file!\n"
     ]
    }
   ],
   "source": [
    "# Save the extracted features for both test and train images for later use using H5PY library\n",
    "\n",
    "# Read and close file first\n",
    "h5py_test_file = h5py.File(dataset_root + 'test_images_fc7_features.h5', 'r+')\n",
    "h5py_test_file.close()\n",
    "\n",
    "\n",
    "\n",
    "# Open a h5py file for writing testing features extracted using bvlc reference model\n",
    "h5py_test_file = h5py.File(dataset_root + 'test_images_fc7_features.h5','w')\n",
    "\n",
    "# Create dataset for image name\n",
    "h5py_test_img_name = h5py_test_file.create_dataset('image_name', (0,), maxshape=(None,), dtype='|S54')\n",
    "\n",
    "# Create dataset for image features\n",
    "# Save features returned from bvlc fc7 layer (4096 features) to h5py file\n",
    "h5py_test_img_feature = h5py_test_file.create_dataset('image_feature', (0,4096), maxshape = (None,4096))\n",
    "\n",
    "h5py_test_file.close()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Created Test image features file!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test photos to business id: 1190225\n",
      "Total unique test photos: 237152\n",
      "Total test images: 237152\n"
     ]
    }
   ],
   "source": [
    "print(\"Total test photos to business id: {}\".format(len(test_photos_to_business_id)))\n",
    "\n",
    "print(\"Total unique test photos: {}\".format(len(test_photos_to_business_id['photo_id'].unique())))\n",
    "\n",
    "\n",
    "# Get the Image full path using photo list from csv file\n",
    "test_images = [os.path.join(test_dataset_root + 'test_photos/', str(x) + '.jpg') for x in test_photos_to_business_id['photo_id'].unique()]\n",
    "\n",
    "total_test_images = len(test_images)\n",
    "print(\"Total test images: {}\".format(total_test_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test images processed: 1000\n",
      "Total test images processed: 2000\n",
      "Total test images processed: 3000\n",
      "Total test images processed: 4000\n",
      "Total test images processed: 5000\n",
      "Total test images processed: 6000\n",
      "Total test images processed: 7000\n",
      "Total test images processed: 8000\n",
      "Total test images processed: 9000\n",
      "Total test images processed: 10000\n",
      "Total test images processed: 11000\n",
      "Total test images processed: 12000\n",
      "Total test images processed: 13000\n",
      "Total test images processed: 14000\n",
      "Total test images processed: 15000\n",
      "Total test images processed: 16000\n",
      "Total test images processed: 17000\n",
      "Total test images processed: 18000\n",
      "Total test images processed: 19000\n",
      "Total test images processed: 20000\n",
      "Total test images processed: 21000\n",
      "Total test images processed: 22000\n",
      "Total test images processed: 23000\n",
      "Total test images processed: 24000\n",
      "Total test images processed: 25000\n",
      "Total test images processed: 26000\n",
      "Total test images processed: 27000\n",
      "Total test images processed: 28000\n",
      "Total test images processed: 29000\n",
      "Total test images processed: 30000\n",
      "Total test images processed: 31000\n",
      "Total test images processed: 32000\n",
      "Total test images processed: 33000\n",
      "Total test images processed: 34000\n",
      "Total test images processed: 35000\n",
      "Total test images processed: 36000\n",
      "Total test images processed: 37000\n",
      "Total test images processed: 38000\n",
      "Total test images processed: 39000\n",
      "Total test images processed: 40000\n",
      "Total test images processed: 41000\n",
      "Total test images processed: 42000\n",
      "Total test images processed: 43000\n",
      "Total test images processed: 44000\n",
      "Total test images processed: 45000\n",
      "Total test images processed: 46000\n",
      "Total test images processed: 47000\n",
      "Total test images processed: 48000\n",
      "Total test images processed: 49000\n",
      "Total test images processed: 50000\n",
      "Total test images processed: 51000\n",
      "Total test images processed: 52000\n",
      "Total test images processed: 53000\n",
      "Total test images processed: 54000\n",
      "Total test images processed: 55000\n",
      "Total test images processed: 56000\n",
      "Total test images processed: 57000\n",
      "Total test images processed: 58000\n",
      "Total test images processed: 59000\n",
      "Total test images processed: 60000\n",
      "Total test images processed: 61000\n",
      "Total test images processed: 62000\n",
      "Total test images processed: 63000\n",
      "Total test images processed: 64000\n",
      "Total test images processed: 65000\n",
      "Total test images processed: 66000\n",
      "Total test images processed: 67000\n",
      "Total test images processed: 68000\n",
      "Total test images processed: 69000\n",
      "Total test images processed: 70000\n",
      "Total test images processed: 71000\n",
      "Total test images processed: 72000\n",
      "Total test images processed: 73000\n",
      "Total test images processed: 74000\n",
      "Total test images processed: 75000\n",
      "Total test images processed: 76000\n",
      "Total test images processed: 77000\n",
      "Total test images processed: 78000\n",
      "Total test images processed: 79000\n",
      "Total test images processed: 80000\n",
      "Total test images processed: 81000\n",
      "Total test images processed: 82000\n",
      "Total test images processed: 83000\n",
      "Total test images processed: 84000\n",
      "Total test images processed: 85000\n",
      "Total test images processed: 86000\n",
      "Total test images processed: 87000\n",
      "Total test images processed: 88000\n",
      "Total test images processed: 89000\n",
      "Total test images processed: 90000\n",
      "Total test images processed: 91000\n",
      "Total test images processed: 92000\n",
      "Total test images processed: 93000\n",
      "Total test images processed: 94000\n",
      "Total test images processed: 95000\n",
      "Total test images processed: 96000\n",
      "Total test images processed: 97000\n",
      "Total test images processed: 98000\n",
      "Total test images processed: 99000\n",
      "Total test images processed: 100000\n",
      "Total test images processed: 101000\n",
      "Total test images processed: 102000\n",
      "Total test images processed: 103000\n",
      "Total test images processed: 104000\n",
      "Total test images processed: 105000\n",
      "Total test images processed: 106000\n",
      "Total test images processed: 107000\n",
      "Total test images processed: 108000\n",
      "Total test images processed: 109000\n",
      "Total test images processed: 110000\n",
      "Total test images processed: 111000\n",
      "Total test images processed: 112000\n",
      "Total test images processed: 113000\n",
      "Total test images processed: 114000\n",
      "Total test images processed: 115000\n",
      "Total test images processed: 116000\n",
      "Total test images processed: 117000\n",
      "Total test images processed: 118000\n",
      "Total test images processed: 119000\n",
      "Total test images processed: 120000\n",
      "Total test images processed: 121000\n",
      "Total test images processed: 122000\n",
      "Total test images processed: 123000\n",
      "Total test images processed: 124000\n",
      "Total test images processed: 125000\n",
      "Total test images processed: 126000\n",
      "Total test images processed: 127000\n",
      "Total test images processed: 128000\n",
      "Total test images processed: 129000\n",
      "Total test images processed: 130000\n",
      "Total test images processed: 131000\n",
      "Total test images processed: 132000\n",
      "Total test images processed: 133000\n",
      "Total test images processed: 134000\n",
      "Total test images processed: 135000\n",
      "Total test images processed: 136000\n",
      "Total test images processed: 137000\n",
      "Total test images processed: 138000\n",
      "Total test images processed: 139000\n",
      "Total test images processed: 140000\n",
      "Total test images processed: 141000\n",
      "Total test images processed: 142000\n",
      "Total test images processed: 143000\n",
      "Total test images processed: 144000\n",
      "Total test images processed: 145000\n",
      "Total test images processed: 146000\n",
      "Total test images processed: 147000\n",
      "Total test images processed: 148000\n",
      "Total test images processed: 149000\n",
      "Total test images processed: 150000\n",
      "Total test images processed: 151000\n",
      "Total test images processed: 152000\n",
      "Total test images processed: 153000\n",
      "Total test images processed: 154000\n",
      "Total test images processed: 155000\n",
      "Total test images processed: 156000\n",
      "Total test images processed: 157000\n",
      "Total test images processed: 158000\n",
      "Total test images processed: 159000\n",
      "Total test images processed: 160000\n",
      "Total test images processed: 161000\n",
      "Total test images processed: 162000\n",
      "Total test images processed: 163000\n",
      "Total test images processed: 164000\n",
      "Total test images processed: 165000\n",
      "Total test images processed: 166000\n",
      "Total test images processed: 167000\n",
      "Total test images processed: 168000\n",
      "Total test images processed: 169000\n",
      "Total test images processed: 170000\n",
      "Total test images processed: 171000\n",
      "Total test images processed: 172000\n",
      "Total test images processed: 173000\n",
      "Total test images processed: 174000\n",
      "Total test images processed: 175000\n",
      "Total test images processed: 176000\n",
      "Total test images processed: 177000\n",
      "Total test images processed: 178000\n",
      "Total test images processed: 179000\n",
      "Total test images processed: 180000\n",
      "Total test images processed: 181000\n",
      "Total test images processed: 182000\n",
      "Total test images processed: 183000\n",
      "Total test images processed: 184000\n",
      "Total test images processed: 185000\n",
      "Total test images processed: 186000\n",
      "Total test images processed: 187000\n",
      "Total test images processed: 188000\n",
      "Total test images processed: 189000\n",
      "Total test images processed: 190000\n",
      "Total test images processed: 191000\n",
      "Total test images processed: 192000\n",
      "Total test images processed: 193000\n",
      "Total test images processed: 194000\n",
      "Total test images processed: 195000\n",
      "Total test images processed: 196000\n",
      "Total test images processed: 197000\n",
      "Total test images processed: 198000\n",
      "Total test images processed: 199000\n",
      "Total test images processed: 200000\n",
      "Total test images processed: 201000\n",
      "Total test images processed: 202000\n",
      "Total test images processed: 203000\n",
      "Total test images processed: 204000\n",
      "Total test images processed: 205000\n",
      "Total test images processed: 206000\n",
      "Total test images processed: 207000\n",
      "Total test images processed: 208000\n",
      "Total test images processed: 209000\n",
      "Total test images processed: 210000\n",
      "Total test images processed: 211000\n",
      "Total test images processed: 212000\n",
      "Total test images processed: 213000\n",
      "Total test images processed: 214000\n",
      "Total test images processed: 215000\n",
      "Total test images processed: 216000\n",
      "Total test images processed: 217000\n",
      "Total test images processed: 218000\n",
      "Total test images processed: 219000\n",
      "Total test images processed: 220000\n",
      "Total test images processed: 221000\n",
      "Total test images processed: 222000\n",
      "Total test images processed: 223000\n",
      "Total test images processed: 224000\n",
      "Total test images processed: 225000\n",
      "Total test images processed: 226000\n",
      "Total test images processed: 227000\n",
      "Total test images processed: 228000\n",
      "Total test images processed: 229000\n",
      "Total test images processed: 230000\n",
      "Total test images processed: 231000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test images processed: 232000\n",
      "Total test images processed: 233000\n",
      "Total test images processed: 234000\n",
      "Total test images processed: 235000\n",
      "Total test images processed: 236000\n",
      "Total test images processed: 237000\n",
      "Total test images processed: 237152\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Batch size to process image features\n",
    "batch_size = 500\n",
    "\n",
    "# Get the features for testing Images\n",
    "for count in range(0, total_test_images, batch_size):\n",
    "    \n",
    "    # Get the image path for this batch of images\n",
    "    image_path = test_images[count: min((count + batch_size), total_test_images)]\n",
    "    \n",
    "    # Get features for all batch images\n",
    "    test_img_features = load_features(image_path, layer='fc7')\n",
    "    \n",
    "    total_processed = (count + test_img_features.shape[0])\n",
    "\n",
    "    \n",
    "    # Open the h5 file to store the image features for future use\n",
    "    h5py_test_file = h5py.File(dataset_root + 'test_images_fc7_features.h5','r+')\n",
    "    \n",
    "    h5py_test_file['image_name'].resize((total_processed,))\n",
    "    h5py_test_file['image_name'][count : total_processed] = np.array(image_path)\n",
    "    \n",
    "    h5py_test_file['image_feature'].resize((total_processed, test_img_features.shape[1]))\n",
    "    h5py_test_file['image_feature'][count : total_processed, :] = test_img_features\n",
    "    h5py_test_file.close()\n",
    "\n",
    "    if (total_processed % 1000) == 0 or total_processed == total_test_images:\n",
    "        print(\"Total test images processed: {}\".format(total_processed))\n",
    "        \n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate train image features to each business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dropping business with no labels\n",
    "y_training_labels = pd.read_csv(dataset_root + 'train.csv').dropna()\n",
    "#print(training_labels[:5])\n",
    "\n",
    "\n",
    "# Convert space delimitted labels into tuples\n",
    "y_training_labels['labels'] = y_training_labels['labels'].apply(lambda labels: tuple(sorted(int(label) for label in labels.split())))\n",
    "#print(training_labels[:5])\n",
    "\n",
    "\n",
    "# Set the main index of labels to business_id\n",
    "y_training_labels.set_index('business_id', inplace=True)\n",
    "#print(\"Training data after setting index to business id\")\n",
    "#print(training_labels[:5])\n",
    "\n",
    "\n",
    "# Get the unique businesses in train file\n",
    "train_business_ids = y_training_labels.index.unique()\n",
    "#print(\"Business id\")\n",
    "#print(business_ids[:5])\n",
    "#print('Total businesses: {}'.format(len(business_ids)))\n",
    "\n",
    "\n",
    "\n",
    "# Load the training features from h5 file\n",
    "X_train_features_file = h5py.File(dataset_root + 'train_images_fc7_features.h5', 'r')\n",
    "X_train_features = np.copy(X_train_features_file['image_feature'])\n",
    "X_train_features_file.close()\n",
    "\n",
    "\n",
    "\n",
    "# Create a new DataFrame to store business, labels along with image features now\n",
    "train_data_frame = pd.DataFrame(columns=['business_id', 'label', 'features'])\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done pass: 1996\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "\n",
    "for business in train_business_ids:\n",
    "    #if count < 1:\n",
    "    #    print('Business: {}'.format(business))\n",
    "    \n",
    "    \n",
    "    label_from_business = y_training_labels.loc[business]['labels']\n",
    "    #if count < 1:\n",
    "    #    print('Labels from business: {}'.format(label_from_business))\n",
    "    \n",
    "    \n",
    "    business_list = train_photos_to_business_id[train_photos_to_business_id['business_id'] == business]\n",
    "    #if count < 1:\n",
    "    #    print('business_list:\\n')\n",
    "    #    print(business_list)\n",
    "    \n",
    "    \n",
    "    business_list_index = train_photos_to_business_id[train_photos_to_business_id['business_id'] == business].index\n",
    "    #if count < 1:\n",
    "    #    print('business_list_index:\\n')\n",
    "    #    print(business_list_index)\n",
    "    \n",
    "    \n",
    "    image_list = train_photos_to_business_id[train_photos_to_business_id['business_id'] == business].index.tolist()\n",
    "    #if count < 1:\n",
    "    #    print('Image_list:\\n')\n",
    "    #    print(image_list)\n",
    "    \n",
    "    \n",
    "    feature_list = X_train_features[image_list]\n",
    "    \n",
    "    #if count < 1:\n",
    "    #    print('feature_list:\\n')\n",
    "    #    print(feature_list)\n",
    "     \n",
    "    \n",
    "    mean_feature = list(np.mean(feature_list, axis=0))\n",
    "    \n",
    "    #if count < 1:\n",
    "    #    print('mean_feature:\\n')\n",
    "    #    print(mean_feature)\n",
    "        \n",
    "    train_data_frame.loc[count] = [business, label_from_business, mean_feature]\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if (count == len(train_business_ids)):\n",
    "        print('Done pass: {}'.format(count))\n",
    "\n",
    "        \n",
    "# Store train data frame to file\n",
    "with open(dataset_root + \"train_business_label_fc7_features.csv\", 'w') as f:  \n",
    "    train_data_frame.to_csv(f, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five features\n",
      "   business_id                  label  \\\n",
      "0         1000  (1, 2, 3, 4, 5, 6, 7)   \n",
      "1         1001           (0, 1, 6, 8)   \n",
      "2          100     (1, 2, 4, 5, 6, 7)   \n",
      "3         1006        (1, 2, 4, 5, 6)   \n",
      "4         1010              (0, 6, 8)   \n",
      "\n",
      "                                            features  \n",
      "0  [0.19977085, 0.43287092, 0.22732987, 0.3551694...  \n",
      "1  [0.0, 0.58893245, 0.53906047, 0.17221628, 0.01...  \n",
      "2  [0.11155061, 0.034822084, 0.12025276, 0.520122...  \n",
      "3  [0.078059338, 0.054452635, 0.05638162, 0.69423...  \n",
      "4  [0.39657032, 0.27962369, 0.0, 0.17205141, 0.36...  \n",
      "Total length of features\n",
      "1996\n"
     ]
    }
   ],
   "source": [
    "# Test if the features saved correctly\n",
    "train_feature_csv = pd.read_csv(dataset_root + 'train_business_label_fc7_features.csv')\n",
    "\n",
    "print('First five features')\n",
    "print(train_feature_csv[:5])\n",
    "print('Total length of features')\n",
    "print(len(train_feature_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate Augmented training image features to each business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   business_id labels        photo_id\n",
      "0         2805      7   52779_rotated\n",
      "1          485    4 7  278973_rotated\n",
      "2          485    4 7  195284_rotated\n",
      "3          485    4 7   19992_rotated\n",
      "4          485    4 7   80748_rotated\n",
      "Done!\n",
      "1352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aug_rotated_data_frame_copy = aug_rotated_data_frame.copy()\n",
    "aug_gamma_data_frame_copy = aug_gamma_data_frame.copy()\n",
    "\n",
    "# Convert space delimitted labels into tuples\n",
    "#aug_rotated_data_frame_copy['labels'] = aug_rotated_data_frame_copy['labels'].apply(lambda labels: tuple(sorted(int(label) for label in labels.split())))\n",
    "#aug_gamma_data_frame_copy['labels'] = aug_gamma_data_frame_copy['labels'].apply(lambda labels: tuple(sorted(int(label) for label in labels.split())))\n",
    "\n",
    "print(aug_rotated_data_frame_copy[:5])\n",
    "\n",
    "\n",
    "# Set the main index of labels to business_id\n",
    "aug_rotated_data_frame_copy.set_index('business_id', inplace=True)\n",
    "aug_gamma_data_frame_copy.set_index('business_id', inplace=True)\n",
    "\n",
    "\n",
    "# Get the unique businesses in train file\n",
    "aug_rotated_train_business_ids = aug_rotated_data_frame_copy.index.unique()\n",
    "aug_gamma_train_business_ids = aug_gamma_data_frame_copy.index.unique()\n",
    "\n",
    "print('Done!')\n",
    "print(len(aug_rotated_train_business_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load the training features from h5 file\n",
    "X_aug_rotated_train_features_file = h5py.File(dataset_root + 'aug_rotated_train_images_fc7_features.h5', 'r')\n",
    "X_aug_rotated_train_features = np.copy(X_aug_rotated_train_features_file['image_feature'])\n",
    "X_aug_rotated_train_features_file.close()\n",
    "\n",
    "\n",
    "X_aug_gamma_train_features_file = h5py.File(dataset_root + 'aug_gamma_train_images_fc7_features.h5', 'r')\n",
    "X_aug_gamma_train_features = np.copy(X_aug_gamma_train_features_file['image_feature'])\n",
    "X_aug_gamma_train_features_file.close()\n",
    "\n",
    "# Create a new DataFrame to store business, labels along with image features now\n",
    "final_aug_rotated_train_data_frame = pd.DataFrame(columns=['business_id', 'label', 'features'])\n",
    "final_aug_gamma_train_data_frame = pd.DataFrame(columns=['business_id', 'label', 'features'])\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business: 2805\n",
      "Labels from business: ['7']\n",
      "Image_list:\n",
      "\n",
      "[0, 1759, 1760, 8537, 8912, 10941, 11823, 15426, 15427, 16366, 16923, 17009, 17560, 17561, 17581, 17582, 17583, 17584, 17671, 21879, 22724, 25338, 26104, 29505, 44081, 44082, 45525, 45637, 45638, 45639, 49286, 54676, 54677, 55714, 55715, 59523, 63812, 63892, 66640, 67215, 67216, 67217, 69772, 69773, 70338, 70339, 70340, 75600, 75927, 85082, 85163, 87522, 90366, 92899, 94099, 97422, 97423, 102822, 103107, 103108, 103113, 107592, 107607, 107608, 107609, 107610, 107611, 108257, 108258, 108259, 111574, 111575, 112403, 113867, 118954, 118960, 118961, 118976, 121753, 121754, 122562, 125519, 125520, 125521, 125792, 126348, 128441, 128753, 128754, 129914, 140914, 149034, 149035, 149037, 153122, 153986, 153987, 153989, 153990, 153991, 153992, 153996, 153997, 153998, 153999, 156053, 157105, 157106, 157107, 157108, 157109, 157110, 157111, 157615, 161006, 161007, 161010, 162522, 164322]\n",
      "Total processed: 1352\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for business in aug_rotated_train_business_ids:\n",
    "    if count < 1:\n",
    "        print('Business: {}'.format(business))\n",
    "    \n",
    "    label_from_business = aug_rotated_data_frame_copy.loc[business]['labels'].unique()\n",
    "    \n",
    "    if count < 1:\n",
    "        print('Labels from business: {}'.format(label_from_business))\n",
    "    \n",
    "    \n",
    "    image_list = aug_rotated_data_frame[aug_rotated_data_frame['business_id'] == business].index.tolist()\n",
    "    if count < 1:\n",
    "        print('Image_list:\\n')\n",
    "        print(image_list)\n",
    "    \n",
    "    \n",
    "    feature_list = X_aug_rotated_train_features[image_list]\n",
    "    \n",
    "    #if count < 1:\n",
    "    #    print('feature_list:\\n')\n",
    "    #    print(feature_list)\n",
    "     \n",
    "    \n",
    "    mean_feature = list(np.mean(feature_list, axis=0))\n",
    "    \n",
    "    #if count < 1:\n",
    "    #    print('mean_feature:\\n')\n",
    "    #    print(mean_feature)\n",
    "        \n",
    "    final_aug_rotated_train_data_frame.loc[count] = [business, label_from_business, mean_feature]\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if (count%10000 == 0) or (count == len(aug_rotated_train_business_ids)):\n",
    "        print('Total processed: {}'.format(count))\n",
    "\n",
    "        \n",
    "# Store train data frame to file\n",
    "with open(dataset_root + \"aug_rotated_train_business_label_fc7_features.csv\", 'w') as f:  \n",
    "    final_aug_rotated_train_data_frame.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   business_id    label                                           features\n",
      "0         2805    ['7']  [0.37602994, 0.34450653, 0.13633271, 0.2259040...\n",
      "1          485  ['4 7']  [0.4303605, 0.25506508, 0.17580706, 0.20345241...\n",
      "2         1783    ['7']  [0.31403202, 0.20694035, 0.10624066, 0.1678360...\n",
      "3         3216    ['7']  [0.35157824, 0.083742946, 0.20816316, 0.144753...\n",
      "4         3385    ['4']  [0.57048815, 0.31142053, 0.068942636, 0.263724...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_aug_rotated_train_data_frame = pd.read_csv(dataset_root + 'aug_rotated_train_business_label_fc7_features.csv')\n",
    "print(final_aug_rotated_train_data_frame[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business: 2805\n",
      "Labels from business: ['7']\n",
      "Image_list:\n",
      "\n",
      "[0, 1759, 1760, 8537, 8912, 10941, 11823, 15426, 15427, 16366, 16923, 17009, 17560, 17561, 17581, 17582, 17583, 17584, 17671, 21879, 22724, 25338, 26104, 29505, 44081, 44082, 45525, 45637, 45638, 45639, 49286, 54676, 54677, 55714, 55715, 59523, 63812, 63892, 66640, 67215, 67216, 67217, 69772, 69773, 70338, 70339, 70340, 75600, 75927, 85082, 85163, 87522, 90366, 92899, 94099, 97422, 97423, 102822, 103107, 103108, 103113, 107592, 107607, 107608, 107609, 107610, 107611, 108257, 108258, 108259, 111574, 111575, 112403, 113867, 118954, 118960, 118961, 118976, 121753, 121754, 122562, 125519, 125520, 125521, 125792, 126348, 128441, 128753, 128754, 129914, 140914, 149034, 149035, 149037, 153122, 153986, 153987, 153989, 153990, 153991, 153992, 153996, 153997, 153998, 153999, 156053, 157105, 157106, 157107, 157108, 157109, 157110, 157111, 157615, 161006, 161007, 161010, 162522, 164322]\n",
      "Total processed: 1352\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for business in aug_gamma_train_business_ids:\n",
    "    if count < 1:\n",
    "        print('Business: {}'.format(business))\n",
    "    \n",
    "    label_from_business = aug_gamma_data_frame_copy.loc[business]['labels'].unique()\n",
    "    \n",
    "    if count < 1:\n",
    "        print('Labels from business: {}'.format(label_from_business))\n",
    "    \n",
    "    \n",
    "    image_list = aug_gamma_data_frame[aug_gamma_data_frame['business_id'] == business].index.tolist()\n",
    "    if count < 1:\n",
    "        print('Image_list:\\n')\n",
    "        print(image_list)\n",
    "    \n",
    "    \n",
    "    feature_list = X_aug_gamma_train_features[image_list]\n",
    "    \n",
    "    #if count < 1:\n",
    "    #    print('feature_list:\\n')\n",
    "    #    print(feature_list)\n",
    "     \n",
    "    \n",
    "    mean_feature = list(np.mean(feature_list, axis=0))\n",
    "    \n",
    "    #if count < 1:\n",
    "    #    print('mean_feature:\\n')\n",
    "    #    print(mean_feature)\n",
    "        \n",
    "    final_aug_gamma_train_data_frame.loc[count] = [business, label_from_business, mean_feature]\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if (count%10000 == 0) or (count == len(aug_gamma_train_business_ids)):\n",
    "        print('Total processed: {}'.format(count))\n",
    "\n",
    "        \n",
    "# Store train data frame to file\n",
    "with open(dataset_root + \"aug_gamma_train_business_label_fc7_features.csv\", 'w') as f:  \n",
    "    final_aug_gamma_train_data_frame.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   business_id    label                                           features\n",
      "0         2805    ['7']  [0.099466562, 0.17942695, 0.30248374, 0.466066...\n",
      "1          485  ['4 7']  [0.17786448, 0.20703655, 0.23062107, 0.4083034...\n",
      "2         1783    ['7']  [0.17781542, 0.12470524, 0.35037681, 0.2263255...\n",
      "3         3216    ['7']  [0.13506195, 0.25203982, 0.23938432, 0.2173104...\n",
      "4         3385    ['4']  [0.19472842, 0.11007848, 0.28000301, 0.5795958...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_aug_gamma_train_data_frame = pd.read_csv(dataset_root + 'aug_gamma_train_business_label_fc7_features.csv')\n",
    "print(final_aug_gamma_train_data_frame[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate testing image features to each business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "## Load mapping of testing Photos to Business IDs\n",
    "test_photo_to_business_id = pd.read_csv(dataset_root + 'test_photo_to_biz.csv')\n",
    "#print(test_photo_to_business_id[:5])\n",
    "\n",
    "test_business_ids = test_photo_to_business_id['business_id'].unique()\n",
    "\n",
    "\n",
    "\n",
    "# Load the testing features from h5 file\n",
    "X_test_features_file = h5py.File(dataset_root + 'test_images_fc7_features.h5', 'r')\n",
    "X_test_image_name = list(np.copy(X_test_features_file['image_name']))\n",
    "X_test_image_features = np.copy(X_test_features_file['image_feature'])\n",
    "X_test_features_file.close()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for train_list_imgs in X_test_image_name:\n",
    "    #print(train_list_imgs)\n",
    "    if \"317818\" in train_list_imgs:\n",
    "        #print(train_list_imgs)\n",
    "        count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ubuntu/test_photos/317818.jpg', '/home/ubuntu/test_photos/30679.jpg', '/home/ubuntu/test_photos/455084.jpg', '/home/ubuntu/test_photos/371381.jpg', '/home/ubuntu/test_photos/86224.jpg']\n",
      "['317818.jpg', '30679.jpg', '455084.jpg', '371381.jpg', '86224.jpg']\n",
      "['317818', '30679', '455084', '371381', '86224']\n"
     ]
    }
   ],
   "source": [
    "print(X_test_image_name[:5])\n",
    "\n",
    "X_test_image_name_short = [name.split('/')[-1] for name in X_test_image_name]\n",
    "\n",
    "print(X_test_image_name_short[:5])\n",
    "\n",
    "X_test_image_name_short_without_ext = [name.split('.')[0] for name in X_test_image_name_short]\n",
    "\n",
    "print(X_test_image_name_short_without_ext[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buisness processed:  100 Time passed:  11.9 sec\n",
      "Buisness processed:  200 Time passed:  26.6 sec\n",
      "Buisness processed:  300 Time passed:  44.1 sec\n",
      "Buisness processed:  400 Time passed:  60.6 sec\n",
      "Buisness processed:  500 Time passed:  79.8 sec\n",
      "Buisness processed:  600 Time passed:  103.4 sec\n",
      "Buisness processed:  700 Time passed:  127.2 sec\n",
      "Buisness processed:  800 Time passed:  153.0 sec\n",
      "Buisness processed:  900 Time passed:  177.6 sec\n",
      "Buisness processed:  1000 Time passed:  199.4 sec\n",
      "Buisness processed:  1100 Time passed:  228.3 sec\n",
      "Buisness processed:  1200 Time passed:  256.1 sec\n",
      "Buisness processed:  1300 Time passed:  285.2 sec\n",
      "Buisness processed:  1400 Time passed:  317.3 sec\n",
      "Buisness processed:  1500 Time passed:  348.1 sec\n",
      "Buisness processed:  1600 Time passed:  378.3 sec\n",
      "Buisness processed:  1700 Time passed:  409.8 sec\n",
      "Buisness processed:  1800 Time passed:  441.1 sec\n",
      "Buisness processed:  1900 Time passed:  474.1 sec\n",
      "Buisness processed:  2000 Time passed:  503.7 sec\n",
      "Buisness processed:  2100 Time passed:  531.7 sec\n",
      "Buisness processed:  2200 Time passed:  567.3 sec\n",
      "Buisness processed:  2300 Time passed:  603.1 sec\n",
      "Buisness processed:  2400 Time passed:  634.3 sec\n",
      "Buisness processed:  2500 Time passed:  667.4 sec\n",
      "Buisness processed:  2600 Time passed:  699.9 sec\n",
      "Buisness processed:  2700 Time passed:  729.3 sec\n",
      "Buisness processed:  2800 Time passed:  754.9 sec\n",
      "Buisness processed:  2900 Time passed:  785.2 sec\n",
      "Buisness processed:  3000 Time passed:  820.7 sec\n",
      "Buisness processed:  3100 Time passed:  863.5 sec\n",
      "Buisness processed:  3200 Time passed:  907.0 sec\n",
      "Buisness processed:  3300 Time passed:  940.6 sec\n",
      "Buisness processed:  3400 Time passed:  971.2 sec\n",
      "Buisness processed:  3500 Time passed:  1000.3 sec\n",
      "Buisness processed:  3600 Time passed:  1046.9 sec\n",
      "Buisness processed:  3700 Time passed:  1082.4 sec\n",
      "Buisness processed:  3800 Time passed:  1115.3 sec\n",
      "Buisness processed:  3900 Time passed:  1156.2 sec\n",
      "Buisness processed:  4000 Time passed:  1187.1 sec\n",
      "Buisness processed:  4100 Time passed:  1218.1 sec\n",
      "Buisness processed:  4200 Time passed:  1250.6 sec\n",
      "Buisness processed:  4300 Time passed:  1284.2 sec\n",
      "Buisness processed:  4400 Time passed:  1328.5 sec\n",
      "Buisness processed:  4500 Time passed:  1367.2 sec\n",
      "Buisness processed:  4600 Time passed:  1405.0 sec\n",
      "Buisness processed:  4700 Time passed:  1441.6 sec\n",
      "Buisness processed:  4800 Time passed:  1477.7 sec\n",
      "Buisness processed:  4900 Time passed:  1510.7 sec\n",
      "Buisness processed:  5000 Time passed:  1540.7 sec\n",
      "Buisness processed:  5100 Time passed:  1573.5 sec\n",
      "Buisness processed:  5200 Time passed:  1609.7 sec\n",
      "Buisness processed:  5300 Time passed:  1641.8 sec\n",
      "Buisness processed:  5400 Time passed:  1677.4 sec\n",
      "Buisness processed:  5500 Time passed:  1708.9 sec\n",
      "Buisness processed:  5600 Time passed:  1739.0 sec\n",
      "Buisness processed:  5700 Time passed:  1776.1 sec\n",
      "Buisness processed:  5800 Time passed:  1816.9 sec\n",
      "Buisness processed:  5900 Time passed:  1846.1 sec\n",
      "Buisness processed:  6000 Time passed:  1877.3 sec\n",
      "Buisness processed:  6100 Time passed:  1911.6 sec\n",
      "Buisness processed:  6200 Time passed:  1950.6 sec\n",
      "Buisness processed:  6300 Time passed:  1980.0 sec\n",
      "Buisness processed:  6400 Time passed:  2016.0 sec\n",
      "Buisness processed:  6500 Time passed:  2050.6 sec\n",
      "Buisness processed:  6600 Time passed:  2078.6 sec\n",
      "Buisness processed:  6700 Time passed:  2106.1 sec\n",
      "Buisness processed:  6800 Time passed:  2144.7 sec\n",
      "Buisness processed:  6900 Time passed:  2183.4 sec\n",
      "Buisness processed:  7000 Time passed:  2222.3 sec\n",
      "Buisness processed:  7100 Time passed:  2257.0 sec\n",
      "Buisness processed:  7200 Time passed:  2290.3 sec\n",
      "Buisness processed:  7300 Time passed:  2322.9 sec\n",
      "Buisness processed:  7400 Time passed:  2357.3 sec\n",
      "Buisness processed:  7500 Time passed:  2390.4 sec\n",
      "Buisness processed:  7600 Time passed:  2420.7 sec\n",
      "Buisness processed:  7700 Time passed:  2460.7 sec\n",
      "Buisness processed:  7800 Time passed:  2498.4 sec\n",
      "Buisness processed:  7900 Time passed:  2535.6 sec\n",
      "Buisness processed:  8000 Time passed:  2566.3 sec\n",
      "Buisness processed:  8100 Time passed:  2598.4 sec\n",
      "Buisness processed:  8200 Time passed:  2630.6 sec\n",
      "Buisness processed:  8300 Time passed:  2659.1 sec\n",
      "Buisness processed:  8400 Time passed:  2697.4 sec\n",
      "Buisness processed:  8500 Time passed:  2733.6 sec\n",
      "Buisness processed:  8600 Time passed:  2768.8 sec\n",
      "Buisness processed:  8700 Time passed:  2810.7 sec\n",
      "Buisness processed:  8800 Time passed:  2844.1 sec\n",
      "Buisness processed:  8900 Time passed:  2882.8 sec\n",
      "Buisness processed:  9000 Time passed:  2915.9 sec\n",
      "Buisness processed:  9100 Time passed:  2945.4 sec\n",
      "Buisness processed:  9200 Time passed:  2974.3 sec\n",
      "Buisness processed:  9300 Time passed:  3017.9 sec\n",
      "Buisness processed:  9400 Time passed:  3048.9 sec\n",
      "Buisness processed:  9500 Time passed:  3082.3 sec\n",
      "Buisness processed:  9600 Time passed:  3123.5 sec\n",
      "Buisness processed:  9700 Time passed:  3168.2 sec\n",
      "Buisness processed:  9800 Time passed:  3204.2 sec\n",
      "Buisness processed:  9900 Time passed:  3246.8 sec\n",
      "Buisness processed:  10000 Time passed:  3283.0 sec\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_data_frame = pd.DataFrame(columns=['business_id', 'features'])\n",
    "count = 0\n",
    "t = time.time()\n",
    "\n",
    "for business in test_business_ids:     \n",
    "    \n",
    "    #print('Processing business ID: {}'.format(business))\n",
    "    \n",
    "    photo_ids = test_photo_to_business_id[test_photo_to_business_id['business_id'] == business]['photo_id'].tolist()  \n",
    "    \n",
    "    #print('Photo IDs: {}'.format(photo_ids))\n",
    "    \n",
    "    #for ph in photo_ids:\n",
    "    #    print('Photo: {}'.format(ph))\n",
    "    #    print('X test: {}'.format(X_test_image_name_short_without_ext.index(str(ph))))\n",
    "    \n",
    "    image_index = [X_test_image_name_short_without_ext.index(str(photo)) for photo in photo_ids]\n",
    "               \n",
    "    test_features = X_test_image_features[image_index]\n",
    "    \n",
    "    test_mean_feature = list(np.mean(test_features, axis=0))\n",
    "\n",
    "    test_data_frame.loc[count] = [business, test_mean_feature]\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if (count % 100) == 0:\n",
    "        print \"Buisness processed: \", count, \"Time passed: \", \"{0:.1f}\".format(time.time()-t), \"sec\"\n",
    "\n",
    "\n",
    "with open(dataset_root+\"test_business_fc7_features.csv\",'w') as f:  \n",
    "    test_data_frame.to_csv(f, index=False)\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003sg</td>\n",
       "      <td>[0.19304767, 0.25836322, 0.19439411, 0.4623304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00er5</td>\n",
       "      <td>[0.19397034, 0.25547439, 0.18416163, 0.3357919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00kad</td>\n",
       "      <td>[0.12130528, 0.12655617, 0.076521836, 0.383440...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00mc6</td>\n",
       "      <td>[0.28427792, 0.11110595, 0.47849005, 0.4494445...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00q7x</td>\n",
       "      <td>[0.23811768, 0.33041945, 0.25544992, 0.3258045...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  business_id                                           features\n",
       "0       003sg  [0.19304767, 0.25836322, 0.19439411, 0.4623304...\n",
       "1       00er5  [0.19397034, 0.25547439, 0.18416163, 0.3357919...\n",
       "2       00kad  [0.12130528, 0.12655617, 0.076521836, 0.383440...\n",
       "3       00mc6  [0.28427792, 0.11110595, 0.47849005, 0.4494445...\n",
       "4       00q7x  [0.23811768, 0.33041945, 0.25544992, 0.3258045..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check file content\n",
    "test_feature_csv = pd.read_csv(dataset_root+'test_business_fc7_features.csv')\n",
    "print test_feature_csv.shape\n",
    "test_feature_csv[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use classifier to train on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_array(str_label):\n",
    "    str_label = str_label[1:-1]\n",
    "    str_label = str_label.split(',')\n",
    "    return [int(x) for x in str_label if len(x)>0]\n",
    "\n",
    "\n",
    "def convert_feature_to_vector(str_feature):\n",
    "    str_feature = str_feature[1:-1]\n",
    "    str_feature = str_feature.split(',')\n",
    "    return [float(x) for x in str_feature]\n",
    "\n",
    "def convert_aug_label_to_array(str_label):\n",
    "    str_label = str_label[2:-2]\n",
    "    str_label = str_label.split(' ')\n",
    "    return [int(x) for x in str_label if len(x)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_values = np.array([convert_feature_to_vector(y) for y in train_feature_csv['features']])\n",
    "\n",
    "y_train_values = np.array([convert_label_to_array(y) for y in train_feature_csv['label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotated augmentation\n",
    "X_aug_rotated_train_values = np.array([convert_feature_to_vector(y) for y in final_aug_rotated_train_data_frame['features']])\n",
    "y_aug_rotated_train_values = np.array([convert_aug_label_to_array(y) for y in final_aug_rotated_train_data_frame['label']])\n",
    "\n",
    "\n",
    "\n",
    "#Gamma adjusted augmentation\n",
    "X_aug_gamma_train_values = np.array([convert_feature_to_vector(y) for y in final_aug_gamma_train_data_frame['features']])\n",
    "y_aug_gamma_train_values = np.array([convert_aug_label_to_array(y) for y in final_aug_gamma_train_data_frame['label']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "X_test_values = np.array([convert_feature_to_vector(y) for y in test_feature_csv['features']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700\n"
     ]
    }
   ],
   "source": [
    "X_final_train_values = np.append(X_train_values, X_aug_rotated_train_values, axis=0)\n",
    "\n",
    "X_final_train_values = np.append(X_final_train_values, X_aug_gamma_train_values, axis=0)\n",
    "print(len(X_final_train_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700\n"
     ]
    }
   ],
   "source": [
    "y_final_train_values = np.append(y_train_values, y_aug_rotated_train_values, axis=0)\n",
    "\n",
    "y_final_train_values = np.append(y_final_train_values, y_aug_gamma_train_values, axis=0)\n",
    "print(len(y_final_train_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Labels\n",
      "[list([1, 2, 3, 4, 5, 6, 7]) list([0, 1, 6, 8]) list([1, 2, 4, 5, 6, 7])\n",
      " list([1, 2, 4, 5, 6]) list([0, 6, 8])]\n",
      "One hot encoded labels\n",
      "[[0 1 1 1 1 1 1 1 0]\n",
      " [1 1 0 0 0 0 1 0 1]\n",
      " [0 1 1 0 1 1 1 1 0]\n",
      " [0 1 1 0 1 1 1 0 0]\n",
      " [1 0 0 0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "#Convert list of labels to binary matrix\n",
    "y_train_one_hot_encoded = mlb.fit_transform(y_final_train_values)\n",
    "\n",
    "print('Original Labels')\n",
    "print(y_final_train_values[:5])\n",
    "\n",
    "print('One hot encoded labels')\n",
    "print(y_train_one_hot_encoded[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed:  834.0 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t=time.time()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "#Convert list of labels to binary matrix\n",
    "y_train_one_hot_encoded = mlb.fit_transform(y_final_train_values)\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final_train_values, y_train_one_hot_encoded, test_size=.25, random_state=random_state)\n",
    "\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "print \"Time passed: \", \"{0:.1f}\".format(time.time()-t), \"sec\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)]\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Classifier details\n",
    "####################\n",
    "\n",
    "print(classifier.estimators_)\n",
    "\n",
    "print(classifier.classes_)\n",
    "\n",
    "print(classifier.multilabel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score using linear SVM :  0.818580477505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print \"F1 score using linear SVM : \", f1_score(y_test, y_predict, average='micro') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a rbf kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed for RBF SVC:  1249.4 sec\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "#Convert list of labels to binary matrix\n",
    "y_train_one_hot_encoded = mlb.fit_transform(y_final_train_values)\n",
    "\n",
    "random_state = np.random.RandomState(10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final_train_values, y_train_one_hot_encoded, test_size=.25, random_state=random_state)\n",
    "\n",
    "rbf_classifier = OneVsRestClassifier(svm.SVC(kernel='rbf', probability=True, random_state=random_state))\n",
    "\n",
    "rbf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_predict = rbf_classifier.predict(X_test)\n",
    "\n",
    "print \"Time passed for RBF SVC: \", \"{0:.1f}\".format(time.time()-t), \"sec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score using rbf kernel SVM :  0.818166638838\n"
     ]
    }
   ],
   "source": [
    "print \"F1 score using rbf kernel SVM : \", f1_score(y_test, y_predict, average='micro') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a SVM using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the data!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-15063365cd5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msvm_grid_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_final_train_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_grid_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Time passed for RBF SVC: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{0:.1f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sec\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "#Convert list of labels to binary matrix\n",
    "y_train_one_hot_encoded = mlb.fit_transform(y_final_train_values)\n",
    "\n",
    "random_state = np.random.RandomState(10)\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 50], 'gamma':[1e-3, 1e-2, 0.2]}\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_final_train_values, y_train_one_hot_encoded, test_size=.25, random_state=random_state)\n",
    "svc = svm.SVC()\n",
    "\n",
    "svm_grid_classifier = OneVsRestClassifier(GridSearchCV(svc, parameters, n_jobs=2, cv=3))\n",
    "\n",
    "print('Fitting the data!')\n",
    "svm_grid_classifier.fit(X_final_train_values, y_train_one_hot_encoded)\n",
    "\n",
    "#y_predict = svm_grid_classifier.predict(X_test)\n",
    "\n",
    "print \"Time passed for RBF SVC: \", \"{0:.1f}\".format(time.time()-t), \"sec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store testing data results for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# Linear SVM\n",
    "########################\n",
    "\n",
    "y_predict_linear_svm = classifier.predict(X_test_values)\n",
    "\n",
    "#Convert binary matrix back to labels\n",
    "y_predict_label_linear_svm = mlb.inverse_transform(y_predict_linear_svm)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "final_test_df = pd.DataFrame(columns=['business_id', 'labels'])\n",
    "\n",
    "for i in range(len(test_feature_csv)):\n",
    "    \n",
    "    biz = test_feature_csv.loc[i]['business_id']\n",
    "    label = y_predict_label_linear_svm[i]\n",
    "    label = str(label)[1:-1].replace(\",\", \" \")\n",
    "    final_test_df.loc[i] = [str(biz), label]\n",
    "\n",
    "with open(dataset_root+\"yelp_test_data_submission_linear_svm.csv\",'w') as f:\n",
    "    final_test_df.to_csv(f, index=False)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# RBF SVM\n",
    "########################\n",
    "\n",
    "y_predict_rbf_svm = rbf_classifier.predict(X_test_values)\n",
    "\n",
    "#Convert binary matrix back to labels\n",
    "y_predict_label_rbf_svm = mlb.inverse_transform(y_predict_rbf_svm)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "final_test_df = pd.DataFrame(columns=['business_id', 'labels'])\n",
    "\n",
    "for i in range(len(test_feature_csv)):\n",
    "    \n",
    "    biz = test_feature_csv.loc[i]['business_id']\n",
    "    label = y_predict_label_rbf_svm[i]\n",
    "    label = str(label)[1:-1].replace(\",\", \" \")\n",
    "    final_test_df.loc[i] = [str(biz), label]\n",
    "\n",
    "with open(dataset_root+\"yelp_test_data_submission_rbf_svm.csv\",'w') as f:\n",
    "    final_test_df.to_csv(f, index=False)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# GridSearchCV SVM\n",
    "########################\n",
    "\n",
    "y_predict_gridsearch_svm = svm_grid_classifier.predict(X_test_values)\n",
    "\n",
    "#Convert binary matrix back to labels\n",
    "y_predict_label_gridsearch_svm = mlb.inverse_transform(y_predict_gridsearch_svm)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "final_test_df = pd.DataFrame(columns=['business_id', 'labels'])\n",
    "\n",
    "for i in range(len(test_feature_csv)):\n",
    "    \n",
    "    biz = test_feature_csv.loc[i]['business_id']\n",
    "    label = y_predict_label_gridsearch_svm[i]\n",
    "    label = str(label)[1:-1].replace(\",\", \" \")\n",
    "    final_test_df.loc[i] = [str(biz), label]\n",
    "\n",
    "with open(dataset_root+\"yelp_test_data_submission_gridsearch_svm.csv\",'w') as f:\n",
    "    final_test_df.to_csv(f, index=False)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 1 1 0 0]\n",
      " [0 1 1 0 0 1 1 0 1]\n",
      " [0 0 0 1 0 1 0 0 1]\n",
      " [0 1 1 0 1 1 1 0 0]\n",
      " [0 1 0 1 1 1 1 0 1]]\n",
      "[(1, 2, 3, 5, 6), (1, 2, 5, 6, 8), (3, 5, 8), (1, 2, 4, 5, 6), (1, 3, 4, 5, 6, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict_linear_svm[:5])\n",
    "print(y_predict_label_linear_svm[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 1 1 0]\n",
      " [0 0 1 0 0 1 1 0 1]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 1 1 0 0]\n",
      " [0 0 0 0 0 1 1 0 0]]\n",
      "[(1, 2, 5, 6, 7), (2, 5, 6, 8), (6,), (4, 5, 6), (5, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict_rbf_svm[:5])\n",
    "print(y_predict_label_rbf_svm[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 1 0 0]\n",
      " [0 1 1 0 0 1 1 0 1]\n",
      " [0 1 1 0 0 1 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 1 1 1 0 0]]\n",
      "[(1, 2, 5, 6), (1, 2, 5, 6, 8), (1, 2, 5, 6), (4,), (1, 4, 5, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict_gridsearch_svm[:5])\n",
    "print(y_predict_label_gridsearch_svm[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free-Form Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ubuntu/yelp_classification/data/yelp_rest_test_image_1.jpg', '/home/ubuntu/yelp_classification/data/yelp_rest_test_image_2.jpg']\n"
     ]
    }
   ],
   "source": [
    "free_form_test_images = ['/home/ubuntu/yelp_classification/data/yelp_rest_test_image_1.jpg', '/home/ubuntu/yelp_classification/data/yelp_rest_test_image_2.jpg']\n",
    "\n",
    "print(free_form_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "free_form_test_images_features = load_features(free_form_test_images, layer='fc7')\n",
    "print(len(free_form_test_images_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "print(len(free_form_test_images_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image-1: /home/ubuntu/yelp_classification/data/yelp_rest_test_image_1.jpg\n",
      "Predicted Labels\n",
      "(0, 6, 8)\n",
      "Image-2: /home/ubuntu/yelp_classification/data/yelp_rest_test_image_2.jpg\n",
      "Predicted Labels\n",
      "(0, 6, 8)\n"
     ]
    }
   ],
   "source": [
    "y_predict_free_form_test_images = rbf_classifier.predict(free_form_test_images_features)\n",
    "\n",
    "#Convert binary matrix back to labels\n",
    "y_predict_free_form_test_images = mlb.inverse_transform(y_predict_free_form_test_images)\n",
    "\n",
    "print('Image-1: {}'.format(free_form_test_images[0]))\n",
    "print(\"Predicted Labels\")\n",
    "print(y_predict_free_form_test_images[0])\n",
    "\n",
    "print('Image-2: {}'.format(free_form_test_images[1]))\n",
    "print(\"Predicted Labels\")\n",
    "print(y_predict_free_form_test_images[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
